{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10915a98",
   "metadata": {},
   "source": [
    "# <center> Predicting Flight Ticket Prices </center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62f69c9",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "* ## [Introduction](#introduction)\n",
    "\n",
    "* ## [Scraped Data EDA](#eda)\n",
    "\n",
    "* ## [Handling Categorical Data](#cat_data)\n",
    "\n",
    "* ## [Features](#features)\n",
    "\n",
    "* ## [Modeling](#modeling)\n",
    "\n",
    "* ## [Saving The Final Model](#model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a302157f",
   "metadata": {},
   "source": [
    "## Introduction: <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f6d5c6e",
   "metadata": {},
   "source": [
    "<b> This is the main notebook for the BetterFly project. I predict ticket prices for upcoming flights in selecting the optimum time for travel and the cheapest flight to the desired destination.\n",
    "The dataset used to train the models is scraped from [Kayak](http://www.kayak.com) which is detailed in the scraper notebook. </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd3b1502",
   "metadata": {},
   "source": [
    "### Importing necessarry libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbd855d2",
   "metadata": {},
   "source": [
    "## Scraped Data EDA: <a class=\"anchor\" id=\"eda\"></a>\n",
    "### Loading the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"dataset/csv\")\n",
    "df_2 = pd.read_csv(\"dataset/csv\")\n",
    "df_3 = pd.read_csv(\"dataset/csv\")\n",
    "df_4 = pd.read_csv(\"dataset/csv\")\n",
    "df_5 = pd.read_csv(\"dataset/csv\")\n",
    "df_6 = pd.read_csv(\"dataset/csv\")\n",
    "df_7 = pd.read_csv(\"dataset/csv\")\n",
    "df_8 = pd.read_csv(\"dataset/csv\")\n",
    "df_9 = pd.read_csv(\"dataset/csv\")\n",
    "df_10 = pd.read_csv(\"datasetcsv\")\n",
    "df_11 = pd.read_csv(\"datasetcsv\")\n",
    "df_12 = pd.read_csv(\"datasetcsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df_1['Source'][0]} => {df_1['Destination'][0]} route has {df_1.shape[0]} trips\")\n",
    "print(f\"{df_2['Source'][0]} => {df_2['Destination'][0]} route has {df_2.shape[0]} trips\")\n",
    "print(f\"{df_3['Source'][0]} => {df_3['Destination'][0]} route has {df_3.shape[0]} trips\")\n",
    "print(f\"{df_4['Source'][0]} => {df_4['Destination'][0]} route has {df_4.shape[0]} trips\")\n",
    "print(f\"{df_5['Source'][0]} => {df_5['Destination'][0]} route has {df_5.shape[0]} trips\")\n",
    "print(f\"{df_6['Source'][0]} => {df_6['Destination'][0]} route has {df_6.shape[0]} trips\")\n",
    "print(f\"{df_7['Source'][0]} => {df_7['Destination'][0]} route has {df_7.shape[0]} trips\")\n",
    "print(f\"{df_8['Source'][0]} => {df_8['Destination'][0]} route has {df_8.shape[0]} trips\")\n",
    "print(f\"{df_9['Source'][0]} => {df_9['Destination'][0]} route has {df_9.shape[0]} trips\")\n",
    "print(f\"{df_10['Source'][0]} => {df_10['Destination'][0]} route has {df_10.shape[0]} trips\")\n",
    "print(f\"{df_11['Source'][0]} => {df_11['Destination'][0]} route has {df_11.shape[0]} trips\")\n",
    "print(f\"{df_12['Source'][0]} => {df_12['Destination'][0]} route has {df_12.shape[0]} trips\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7368c341",
   "metadata": {},
   "source": [
    "### Defining functions to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to numerical format in minutes\n",
    "def clean_duration(duration):\n",
    "    duration = list(duration)\n",
    "    duration_hours = []\n",
    "    duration_mins = []\n",
    "    for i in range(len(duration)):\n",
    "        duration_hours.append(int(duration[i].split(sep = \"h\")[0])) # Extract hours from duration\n",
    "        duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1])) # Extracts only minutes from duration\n",
    "\n",
    "    d = []\n",
    "    for i in range(len(duration)):\n",
    "        d.append(duration_hours[i]*60+duration_mins[i])\n",
    "        \n",
    "    return d\n",
    "\n",
    "# convert price to numerical format in USD\n",
    "def clean_price(price):\n",
    "    price = price.str.replace(',','',regex=True)\n",
    "    price = price.str.replace('SAR','',regex=True)\n",
    "    price = price.str.strip()\n",
    "    price = round(pd.to_numeric(price)/3.75,2)\n",
    "    return price\n",
    "\n",
    "# convert date to datetime format\n",
    "def clean_date(date):\n",
    "    date = pd.to_datetime(date)\n",
    "    return date\n",
    "\n",
    "# get price quantile to deal with outliers\n",
    "def get_price_quantile(price):\n",
    "    Q1 = price.quantile(0.25)\n",
    "    Q3 = price.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_lim = Q1 - 1.5 * IQR\n",
    "    upper_lim = Q3 + 1.5 * IQR\n",
    "    return (lower_lim,upper_lim)\n",
    "\n",
    "# get average of each airline\n",
    "def get_avg_per_airline(x):\n",
    "    # average for trips with multiple airlines\n",
    "    multiple_airlines = x[x[\"Airline\"].str.contains(\",\")]\n",
    "    b = list(multiple_airlines[\"Airline\"].str.split(\",\"))\n",
    "    d = [] # Airline 1\n",
    "    e = [] # Airline 2\n",
    "    for i in range(len(b)):\n",
    "        d.append(b[i][0])\n",
    "        e.append(b[i][1])\n",
    "    for i in range(len(e)):\n",
    "        e[i] = e[i].strip()\n",
    "    m_airlines = list(set(d)) + list(set(e))\n",
    "    column_names = [\"Airline\", \"Average Price\"]\n",
    "    t_ = pd.DataFrame(columns = column_names)\n",
    "    for airline in m_airlines:\n",
    "        t = pd.DataFrame(x[x[\"Airline\"].str.contains(airline)][\"Airline\"])\n",
    "        t[\"Average Price\"] = x[x[\"Airline\"].str.contains(airline)][\"Price\"].mean()\n",
    "        t_ = t_.append(t)\n",
    "    t__ = t_.groupby(\"Airline\",as_index = False)[\"Average Price\"].mean()\n",
    "    k = multiple_airlines.copy()\n",
    "    k = k.merge(t__, on = \"Airline\", how = \"left\")\n",
    "    \n",
    "    # average for trips with single airlines\n",
    "    single_airlines = x[~x[\"Airline\"].str.contains(\",\")]\n",
    "    avg_per_airline = single_airlines.groupby(\"Airline\", as_index = False)[\"Price\"].mean()\n",
    "    avg_per_airline = avg_per_airline.rename(columns={\"Price\" : \"Average Price\"})\n",
    "    temp = single_airlines.copy()\n",
    "    temp = temp.merge(avg_per_airline, on='Airline', how =\"left\")\n",
    "    \n",
    "    temp_1 = temp.groupby(\"Airline\", as_index = False)[\"Average Price\"].mean()\n",
    "    k_1 = k.groupby(\"Airline\", as_index = False)[\"Average Price\"].mean()\n",
    "    k_temp = pd.concat([k_1,temp_1])\n",
    "    y = x.merge(k_temp, on = \"Airline\")\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ce84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_raw = [df_1,df_2,df_3,df_4,df_5,df_6,df_7,df_8,df_9,df_10,df_11,df_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11331c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "dfs = []\n",
    "for df in dfs_raw:\n",
    "    df.drop_duplicates() # drop duplicate rows\n",
    "    df[\"Duration\"] = clean_duration(df[\"Duration\"]) # convert duration to numerical minutes format\n",
    "    df[\"Price\"] = clean_price(df[\"Price\"]) # convert price to numerical format in USD\n",
    "    df[\"Date\"] = clean_date(df[\"Date\"]) # convert date to datetime format\n",
    "    dfs.append(get_avg_per_airline(df)) # get average per airline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ce3b7c0",
   "metadata": {},
   "source": [
    "### Studying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a17af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# boxplots for each route\n",
    "k=0\n",
    "figure, axis = plt.subplots(4, 3, figsize=(15,15))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        axis[i,j].boxplot(dfs[k]['Price'])\n",
    "        axis[i,j].set_title(f\"{dfs[k]['Source'][0]} TO {dfs[k]['Destination'][0]}\")\n",
    "        k += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "681fa046",
   "metadata": {},
   "source": [
    "#### It is apparent that all routes have outliers, so we'll deal with them by IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quantile to deal with outliers\n",
    "lower = []\n",
    "upper = []\n",
    "for df in dfs:\n",
    "    x = get_price_quantile(df['Price'])\n",
    "    lower.append(x[0])\n",
    "    upper.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "k = 0\n",
    "for df in dfs:\n",
    "    low = df['Price'] < lower[k]\n",
    "    up = df['Price'] > upper[k]\n",
    "    df['Price'] = df['Price'][~(low|up)]\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop = True,inplace=True)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for each route after dealing with outliers\n",
    "k=0\n",
    "figure, axis = plt.subplots(4, 3, figsize=(15,15))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        axis[i,j].boxplot(dfs[k]['Price'])\n",
    "        axis[i,j].set_title(f\"{dfs[k]['Source'][0]} TO {dfs[k]['Destination'][0]}\")\n",
    "        k += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a9e2aab",
   "metadata": {},
   "source": [
    "#### Now the data is much better, the total dropped data is 5,266 rows out of 55,363."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb203a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all routes into one dataframe\n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86b55b03",
   "metadata": {},
   "source": [
    "## Handling Categorical Data: <a class=\"anchor\" id=\"cat_data\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7446238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the Airline column will be replaced by the average price per airline.\n",
    "df.drop(\"Airline\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "df[\"Source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eff4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source vs price\n",
    "sns.catplot(y = \"Price\", x= \"Source\", data = df.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39508f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing OneHotEncoding on Source since it's nominal categorical data  \n",
    "source =df[[\"Source\"]]\n",
    "source =pd.get_dummies(source, drop_first=True)\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf024fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination\n",
    "df[\"Destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254be453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination vs price\n",
    "sns.catplot(y = \"Price\", x= \"Destination\", data = df.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a205f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing OneHotEncoding on Destination since it's nominal categorical data\n",
    "destination = df[[\"Destination\"]]\n",
    "destination = pd.get_dummies(destination, drop_first=True)\n",
    "destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total stops\n",
    "print(df[\"Total stops\"].value_counts())\n",
    "df[\"Total stops\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935598c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing LabelEncoder on Total stops since it's ordinal categorical data\n",
    "df.replace({\"nonstop \":0, \"1 stop \": 1, \"2 stops \": 2, \"3 stops \":3}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf55917",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df,source,destination], axis=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac035b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date since it'll not be used as a feature\n",
    "final_df.drop([\"Source\",\"Destination\",\"Date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db701a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b244184c",
   "metadata": {},
   "source": [
    "## Features: <a class=\"anchor\" id=\"features\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39fd1cb",
   "metadata": {},
   "source": [
    "#### After constructing the final dataframe with all numerical values, now we can analyze the features that will be used for the regressions models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['Duration', 'Total stops', 'Average Price', 'Source_PAR',\n",
    "       'Source_RUH', 'Source_SVO', 'Destination_PAR', 'Destination_RUH',\n",
    "       'Destination_SVO']]\n",
    "\n",
    "y = final_df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,18))\n",
    "\n",
    "sns.heatmap(final_df.corr(),annot= True, cmap = \"coolwarm\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad192d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature importance to the target variable \"Price\".\n",
    "selection =ExtraTreesRegressor()\n",
    "selection.fit(X,y)\n",
    "selection.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98cd80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting graph of important features\n",
    "plt.figure(figsize = (12,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_,index = X.columns)\n",
    "feat_importances.nlargest(20).plot(kind=\"barh\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0106f5",
   "metadata": {},
   "source": [
    "## Modeling: <a class=\"anchor\" id=\"modeling\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e742a8d4",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% Train - 20% Val - 20% Test\n",
    "\n",
    "X_train_or, X_test, y_train_or, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_or, y_train_or, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "156f3ea4",
   "metadata": {},
   "source": [
    "### Defining a function to get metrics for val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441256e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model):\n",
    "    print(f'Train score {model.score(X_train, y_train)}')\n",
    "    print(f'Val score {model.score(X_val, y_val)}')\n",
    "    print(\"MAE:\" , metrics.mean_absolute_error(y_val,model.predict(X_val)))\n",
    "    print(\"MSE:\" , metrics.mean_squared_error(y_val,model.predict(X_val)))\n",
    "    print(\"RMSE:\" , np.sqrt(metrics.mean_squared_error(y_val,model.predict(X_val))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae28b62",
   "metadata": {},
   "source": [
    "### Baseline Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e08ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "score = lr.score(X_val, y_val)\n",
    "get_metrics(lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "796b82ff",
   "metadata": {},
   "source": [
    "### Polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in [1,2,3,4,5]:\n",
    "    poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly.fit(X_train, y_train)\n",
    "    print(\"-\"*20)\n",
    "    print(\"Degree\", degree)\n",
    "    get_metrics(poly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca27f6e",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffff082",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "get_metrics(lasso_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb6de57d",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e98a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "get_metrics(ridge_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c33c050",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206bad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EN_model = ElasticNet(alpha=1)\n",
    "EN_model.fit(X_train, y_train)\n",
    "EN_model.score(X_val, y_val)\n",
    "get_metrics(EN_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4cd1ed9",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "get_metrics(rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4212c44a",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e64211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get metrics for scaled features\n",
    "def scaled_metrics(model):\n",
    "    print(f'Train score {model.score(X_train_scaled, y_train)}')\n",
    "    print(f'Val score {model.score(X_val_scaled, y_val)}')\n",
    "    print(\"MAE:\" , metrics.mean_absolute_error(y_val,model.predict(X_val_scaled)))\n",
    "    print(\"MSE:\" , metrics.mean_squared_error(y_val,model.predict(X_val_scaled)))\n",
    "    print(\"RMSE:\" , np.sqrt(metrics.mean_squared_error(y_val,model.predict(X_val_scaled))))\n",
    "\n",
    "    \n",
    "## Baseline: Linear Regression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "score = lr.score(X_val_scaled, y_val)\n",
    "print(\"LR\")\n",
    "scaled_metrics(lr)\n",
    "print(\"-\"*50)\n",
    "\n",
    "## Polynomial\n",
    "\n",
    "for degree in [1,2,3,4,5]:\n",
    "    poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly.fit(X_train, y_train)\n",
    "    print(\"Polynomial - Degree\", degree)\n",
    "    scaled_metrics(poly)\n",
    "    print(\"-\"*50)\n",
    "\n",
    "## Lasso\n",
    "\n",
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "print(\"Lasso\")\n",
    "scaled_metrics(lasso_model)\n",
    "print(\"-\"*50)\n",
    "\n",
    "## Ridge\n",
    "\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "print(\"Ridge\")\n",
    "scaled_metrics(ridge_model)\n",
    "print(\"-\"*50)\n",
    "\n",
    "## ElasticNet\n",
    "\n",
    "EN_model = ElasticNet(alpha=1)\n",
    "EN_model.fit(X_train_scaled, y_train)\n",
    "EN_model.score(X_val_scaled, y_val)\n",
    "print(\"ElasticNet\")\n",
    "scaled_metrics(EN_model)\n",
    "print(\"-\"*50)\n",
    "\n",
    "## Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "print(\"Random Forest\")\n",
    "scaled_metrics(rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75cc932b",
   "metadata": {},
   "source": [
    "#### Feature scaling was of no use, it did not improve anything.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f89831d",
   "metadata": {},
   "source": [
    "**<br>From the above analysis, we can see that the random forest model performed the best with:</br>**\n",
    "\n",
    "**Train score 0.9648778537711422**\n",
    "**<br>Val score 0.9448134490695079</br>**\n",
    "**<br>MAE: 61.717733027545194</br>**\n",
    "**<br>MSE: 40035.31608101726</br>**\n",
    "**<br>RMSE: 200.0882707232417</br>**\n",
    "\n",
    "**So, we'll select it as our model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b048733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining the random forest model on train + val, and scoring on test\n",
    "\n",
    "X_train_val = pd.concat([X_train,X_val])\n",
    "y_train_val = pd.concat([y_train,y_val])\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train_val,y_train_val)\n",
    "\n",
    "print(f'Train score {rf.score(X_train_val, y_train_val)}')\n",
    "print(f'Test score {rf.score(X_test, y_test)}')\n",
    "print(\"MAE:\" , metrics.mean_absolute_error(y_test,rf.predict(X_test)))\n",
    "print(\"MSE:\" , metrics.mean_squared_error(y_test,rf.predict(X_test)))\n",
    "print(\"RMSE:\" , np.sqrt(metrics.mean_squared_error(y_test,rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_val_pred = rf.predict(X_train_val)\n",
    "y_test_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_test_pred,alpha =0.2,color=\"DarkBlue\")\n",
    "plt.title('Actual vs. Predicted Airline Prices')\n",
    "plt.xlabel('Predicted Airline Prices')\n",
    "plt.ylabel('Actual Airline Prices');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421d1f3c",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8711a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search CV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af883f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56390fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,prediction,alpha =0.2,color=\"DarkBlue\")\n",
    "plt.title('Actual vs. Predicted Airline Prices')\n",
    "plt.xlabel('Predicted Airline Prices')\n",
    "plt.ylabel('Actual Airline Prices');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE:\" , metrics.mean_absolute_error(y_test,prediction))\n",
    "print(\"MSE:\" , metrics.mean_squared_error(y_test,prediction))\n",
    "print(\"RMSE:\" , np.sqrt(metrics.mean_squared_error(y_test,prediction)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e85d0981",
   "metadata": {},
   "source": [
    "#### Therefore, hyperparameter tuning did not improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    \"Predicted Price\" : rf.predict(X_test),\n",
    "    \"Actual Price\" : y_test,\n",
    "}).reset_index(drop = True)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f134f34",
   "metadata": {},
   "source": [
    "## Saving The Final Model: <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "file = open('rf_flight_prediction.pkl', 'wb')\n",
    "pkl.dump(rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d7102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the model\n",
    "model = open('rf_flight_prediction.pkl','rb')\n",
    "rf_flight_prediction = pkl.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 score {metrics.r2_score(y_test,rf_flight_prediction.predict(X_test))}')\n",
    "print(\"MAE:\" , metrics.mean_absolute_error(y_test,rf_flight_prediction.predict(X_test)))\n",
    "print(\"MSE:\" , metrics.mean_squared_error(y_test,rf_flight_prediction.predict(X_test)))\n",
    "print(\"RMSE:\" , np.sqrt(metrics.mean_squared_error(y_test,rf_flight_prediction.predict(X_test))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91bcaf45",
   "metadata": {},
   "source": [
    "### Therefore, the final model is able to predict flight ticket prices within around  ≈ $61.87"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
